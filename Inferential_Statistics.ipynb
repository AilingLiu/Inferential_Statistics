{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inferential_Statistics.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_5c7FaPekoFx",
        "aj-PMwiGcXt0",
        "jxJRP4FybcCX",
        "DMMTVNLlv29p",
        "FCTNnyPWuxaf",
        "I1ZOoNtJve07",
        "7AwBkp2M0I0a"
      ],
      "authorship_tag": "ABX9TyMgmLzTs+3ClRrtwhhpDwnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AilingLiu/Inferential_Statistics/blob/master/Inferential_Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM1gu2PdkFEo",
        "colab_type": "text"
      },
      "source": [
        "This notebook summarizes the testing methods from <b>Inferential Statitistics </b> course taught by <u>University of Amsterdam</u> on [Coursera](https://www.coursera.org/learn/inferential-statistics). The course had taught how to conduct statistical test usng R. Here, I am using Python to do the test. All the formulas used in this document can be found [here](https://github.com/AilingLiu/Inferential_Statistics/blob/master/FormulasTables.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAjFEUYoqgZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as st"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5c7FaPekoFx",
        "colab_type": "text"
      },
      "source": [
        "# Compare Two Groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRdF7oOMk0Xm",
        "colab_type": "text"
      },
      "source": [
        "<b>Construct Hypotheses</b>\n",
        "\n",
        "When we are testing between two competing hypotheses, a null hypothesis $H_0$ and an alternative hypothesis $H_1$, we generally assume that the null hypothesis is true unless the data shows a strong indication that this is not the case. \n",
        "\n",
        "By doing hypotheses testing, we <u>test the probability of finding a sample statistic given that the null hypothesis is true</u>. If the null hypothesis is true, the difference between a sample statistics and the population parameter is <b>due to sampling error</b>, that is, fluctuations in the sample from the population. However, **if the probability of finding a sample statistic as extreme as ours under the null hypothesis is very small, we generally reject the null hypothesis**.\n",
        "\n",
        "> Test your understanding:\n",
        "\n",
        "\n",
        "1.   Imagine we have found a p value of 0.30 called p1 and another p value of 0.02 called p2, do these p values indicate strong evidence or weak evidence in favour of the null hypothesis? \n",
        ">> Answer: p1 indicates strong evidence in favour of the null hypothesis; p2 indicates weak evidence in favour of the null hypothesis.\n",
        "2.   What does a p value of 0.20 mean?\n",
        ">> Answer: A p value of 0.20 means that there's a probability of 20% of obtaining a similar result or more extreme given that the null hypothesis is true\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj-PMwiGcXt0",
        "colab_type": "text"
      },
      "source": [
        "## Z test to compare two proportions from independent samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfi18O7wceAy",
        "colab_type": "text"
      },
      "source": [
        "We usually calculate two things:\n",
        "\n",
        "1.   The difference between two sample proportions\n",
        "2.   The standard error\n",
        "\n",
        "> Example\n",
        "<br>In this exercise we have a sample of 100 males with a proportion of left wing voters of 0.6 and a sample of 150 females with a proportion of left-wing voters of 0.42. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUxA6ostknT3",
        "colab_type": "code",
        "outputId": "2bb2ad45-499f-426b-8da6-3690fdbc8aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "nmale=100\n",
        "nfemale=150\n",
        "malep=0.6\n",
        "femalep=0.42\n",
        "\n",
        "#pooled proportion\n",
        "poolp=(nmale*malep+nfemale*femalep)/(nmale+nfemale)\n",
        "\n",
        "#standard error under the null hypothesis\n",
        "se=np.sqrt(poolp*(1-poolp)*(1/nmale + 1/nfemale))\n",
        "\n",
        "#z calculated value\n",
        "z_val = (malep - femalep)/se\n",
        "\n",
        "#corresponding p value\n",
        "p_val = (1-st.norm.cdf(z_val))*2\n",
        "\n",
        "sig = 0.05\n",
        "if p_val <=sig:\n",
        "  conclusion='Rejected'\n",
        "else:\n",
        "  conclusion='Not enough evidence to reject'\n",
        "\n",
        "print(f'Calculated Z value: {z_val:.4f}\\nPvalue is: {p_val:.4f} \\nConclusion on Null Hypothesis given {sig} significance level: {conclusion}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated Z value: 2.7889\n",
            "Pvalue is: 0.0053 \n",
            "Conclusion on Null Hypothesis given 0.05 significance level: Rejected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUyGJfsxzr0D",
        "colab_type": "text"
      },
      "source": [
        "Another way to conduct the test is to get the confidence interval of the difference from the two proportions. If 0 (null hypothesis) falls inside the interval, we will reject null hypotheseis. We need two parameters to conduct this test:\n",
        "\n",
        "1.   The z score corresponding to the selected confidence level: $(1-conf)/2$.\n",
        "2.   The standarad error for the difference between two proportions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1933ZnezrGl",
        "colab_type": "code",
        "outputId": "3f5478b7-d818-4032-f8b6-ec359c069a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#z score under given confidence level\n",
        "sig=0.01\n",
        "z_score = np.abs(st.norm.ppf(sig/2))\n",
        "\n",
        "# standard error for the difference\n",
        "sep=np.sqrt(malep*(1-malep)/nmale + femalep*(1-femalep)/nfemale)\n",
        "\n",
        "#lower bound of confidence interval\n",
        "lb = (malep-femalep) - z_score*sep\n",
        "#upper bound of confidence interval\n",
        "ub = (malep-femalep) + z_score*sep\n",
        "\n",
        "print(f'{(1-sig)*100} percent confidence interval:\\n[{lb:.4f}, {ub:.4f}]')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.0 percent confidence interval:\n",
            "[0.0166, 0.3434]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYy3x9-f1fiV",
        "colab_type": "text"
      },
      "source": [
        "There are differences and these differences are significant because the 99% confidence interval does not contain 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB-CBR5TvbMc",
        "colab_type": "text"
      },
      "source": [
        "The equivalent z test for two independent proportions is [proportions_ztest](https://www.statsmodels.org/stable/generated/statsmodels.stats.proportion.proportions_ztest.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS8sgKhXshbq",
        "colab_type": "code",
        "outputId": "bdc72e50-9f98-42fc-fa2c-5e903a4fbf6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "#equivalent in python\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "x_success = np.array([nmale*malep, nfemale*femalep])\n",
        "n_total = np.array([nmale, nfemale])\n",
        "z_val, p_val = proportions_ztest(count=x_success, nobs=n_total, alternative='two-sided')\n",
        "\n",
        "#make a function to give conclusion directly based on pvalue and significance level\n",
        "def testeval(sig, pval):\n",
        "  \n",
        "  \"\"\"\n",
        "  Conclusion of rejection status on null hypothesis given significance level\n",
        "  and the pvalue corresponding to calculated test statistic.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  sig: float\n",
        "    Significance level. Governs the chance of a false positive.\n",
        "      A significance level of 0.05 means that there is a 5% chance of\n",
        "      a false positive.\n",
        "  \n",
        "  pval: float\n",
        "    Calculated p value. The probability of obtaining a similar results\n",
        "    or more extreme given null hypothesis is true.\n",
        "  \n",
        "  Returns:\n",
        "  --------\n",
        "  result: string\n",
        "    Conclusion of rejection status on null hypothesis.\n",
        "  \"\"\"\n",
        "\n",
        "  if pval <=sig:\n",
        "    result = 'Rejected'\n",
        "  else:\n",
        "    result = 'Not enough evidence to reject'\n",
        "  return result\n",
        "\n",
        "siglevel = 0.05\n",
        "conclusion = testeval(siglevel, p_val)\n",
        "print(f'Calculated Z value: {z_val:.4f}\\nPvalue is: {p_val:.4f} \\nConclusion on Null Hypothesis given {siglevel} significance level: {conclusion}\\n')\n",
        "\n",
        "siglevel = 0.01\n",
        "conclusion = testeval(siglevel, p_val)\n",
        "print(f'Calculated Z value: {z_val:.4f}\\nPvalue is: {p_val:.4f} \\nConclusion on Null Hypothesis given {siglevel} significance level: {conclusion}\\n')\n",
        "\n",
        "def prop_confint_2ind(count, nobs, alpha=0.05):\n",
        "  \n",
        "  \"\"\"\n",
        "  A/B test for two proportions;\n",
        "  given a success a trial size of group A and B compute\n",
        "  its confidence interval;\n",
        "  resulting confidence interval matches R's prop.test function\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  count: array\n",
        "      Number of successes in each group\n",
        "\n",
        "  nobs: array\n",
        "      Size, or number of observations in each group\n",
        "\n",
        "  alpha : float, default 0.05\n",
        "      Significance level. Governs the chance of a false positive.\n",
        "      A significance level of 0.05 means that there is a 5% chance of\n",
        "      a false positive. In other words, our confidence level is\n",
        "      1 - 0.05 = 0.95\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  prop_diff : float\n",
        "      Difference between the two proportion\n",
        "\n",
        "  confint : 1d ndarray\n",
        "      Confidence interval of the two proportion test\n",
        "  \"\"\"  \n",
        "\n",
        "  a_success, b_success = count[0], count[1]\n",
        "  a_size, b_size = nobs[0], nobs[1]\n",
        "  a_prop, b_prop = a_success/a_size, b_success/b_size\n",
        "  prop_diff = a_prop-b_prop\n",
        "\n",
        "  #z score under given confidence level\n",
        "  z_score = np.abs(st.norm.ppf(alpha/2))\n",
        "\n",
        "  # standard error for the difference\n",
        "  sep=np.sqrt(a_prop*(1-a_prop)/a_size + b_prop*(1-b_prop)/b_size)\n",
        "\n",
        "  #lower bound of confidence interval\n",
        "  lb = prop_diff - z_score*sep\n",
        "  #upper bound of confidence interval\n",
        "  ub = prop_diff + z_score*sep\n",
        "  return prop_diff, [lb, ub]\n",
        "\n",
        "sig=0.01\n",
        "diff, [lowerb, upperb] = prop_confint_2ind(count=x_success, nobs=n_total, alpha=sig)\n",
        "print(f'{(1-sig)*100} percent confidence interval:\\n[{lowerb:.4f}, {upperb:.4f}]')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated Z value: 2.7889\n",
            "Pvalue is: 0.0053 \n",
            "Conclusion on Null Hypothesis given 0.05 significance level: Rejected\n",
            "\n",
            "Calculated Z value: 2.7889\n",
            "Pvalue is: 0.0053 \n",
            "Conclusion on Null Hypothesis given 0.01 significance level: Rejected\n",
            "\n",
            "99.0 percent confidence interval:\n",
            "[0.0166, 0.3434]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxJRP4FybcCX",
        "colab_type": "text"
      },
      "source": [
        "## T test to compare compare two means from independent samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1PxAS6qcyF2",
        "colab_type": "text"
      },
      "source": [
        "we usually calculate 2 other things first\n",
        "\n",
        "1.   The difference between two independent sample means\n",
        "2.   The standard error of the difference between two independent sample means\n",
        "\n",
        "> Example\n",
        "<br>In this exercise we have a sample of 100 males that do sports on average 4.2 hours per week and a sample of 150 females that do sports on average 5.8 hours per week. \n",
        "*  Case a: the population variances are unequal in two groups\n",
        "*  Case b: the populatin variances are equal in two groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkcYbMG-vXNH",
        "colab_type": "code",
        "outputId": "07baaf26-6eb0-45f8-d8b1-56548ab67cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "#Case a: the population variances are unequal\n",
        "nmale=100\n",
        "malemean=4.2\n",
        "stdmale=2.3\n",
        "nfemale=150\n",
        "femalemean=5.8\n",
        "stdfemale=3.1\n",
        "\n",
        "#standard eror for the difference between two means\n",
        "se=np.sqrt(stdmale**2/nmale+stdfemale**2/nfemale)\n",
        "\n",
        "#mean difference\n",
        "diff=malemean-femalemean\n",
        "\n",
        "#t value\n",
        "t_val=diff/se\n",
        "\n",
        "#degree of freedom\n",
        "df=se**2/((1/(nmale-1)*(stdmale**2/nmale)**2)+(1/(nfemale-1)*(stdfemale**2/nfemale)**2))\n",
        "\n",
        "#calculate the p value\n",
        "pval=(1-st.t.cdf(np.abs(t_val), df))*2\n",
        "siglevel=0.01\n",
        "conclusion=testeval(siglevel, pval)\n",
        "print(f'Calculated T value: {t_val:.4f}\\nPvalue is: {pval:.4f} \\nConclusion on Null Hypothesis given {siglevel} significance level: {conclusion}\\n')\n",
        "\n",
        "# calculate the 99% confidence interval\n",
        "t_score=np.abs(st.t.ppf(siglevel/2, df))\n",
        "lb = diff-t_score*(se)\n",
        "ub = diff+t_score*(se)\n",
        "print(f'{(1-siglevel)*100} percent confidence interval:\\n[{lb:.4f}, {ub:.4f}]')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated T value: -4.6783\n",
            "Pvalue is: 0.0000 \n",
            "Conclusion on Null Hypothesis given 0.01 significance level: Rejected\n",
            "\n",
            "99.0 percent confidence interval:\n",
            "[-2.4817, -0.7183]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbIdtfYngJX3",
        "colab_type": "code",
        "outputId": "c2986199-01c5-454f-e3ab-43b46e48cdbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "#Case b: the population variances are equal\n",
        "nmale=100\n",
        "malemean=4.2\n",
        "nfemale=150\n",
        "femalemean=5.8\n",
        "std=2.8\n",
        "\n",
        "#mean difference\n",
        "diff=malemean-femalemean\n",
        "\n",
        "#pooled standard deviation\n",
        "s=np.sqrt(((nmale-1)*std**2 + (nfemale-1)*std**2)/(nmale-1+nfemale-1))\n",
        "\n",
        "#standard eror for the difference between two means\n",
        "se=s*np.sqrt(1/nmale+1/nfemale)\n",
        "\n",
        "#t value\n",
        "t_val=diff/se\n",
        "\n",
        "#degree of freedom\n",
        "df=nmale+nfemale-2\n",
        "\n",
        "#calculate the p value\n",
        "pval=(1-st.t.cdf(np.abs(t_val), df))*2\n",
        "siglevel=0.01\n",
        "conclusion=testeval(siglevel, pval)\n",
        "print(f'Calculated T value: {t_val:.4f}\\nPvalue is: {pval:.4f} \\nConclusion on Null Hypothesis given {siglevel} significance level: {conclusion}\\n')\n",
        "\n",
        "# calculate the 99% confidence interval\n",
        "t_score=np.abs(st.t.ppf(siglevel/2, df))\n",
        "lb = diff-t_score*(se)\n",
        "ub = diff+t_score*(se)\n",
        "print(f'{(1-siglevel)*100} percent confidence interval:\\n[{lb:.4f}, {ub:.4f}]')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated T value: -4.4263\n",
            "Pvalue is: 0.0000 \n",
            "Conclusion on Null Hypothesis given 0.01 significance level: Rejected\n",
            "\n",
            "99.0 percent confidence interval:\n",
            "[-2.5383, -0.6617]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCL0fklymi0a",
        "colab_type": "text"
      },
      "source": [
        "Equivalent t test for two independent is [ttest_ind](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_ind.html) from scipy or [ttest_ind](https://www.statsmodels.org/stable/generated/statsmodels.stats.weightstats.ttest_ind.html) from statsmodels. Both methods take data points as array directly, without specifically giving mean, standard deviation, or size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QimHYslkxRP",
        "colab_type": "code",
        "outputId": "61ea642e-38f3-4877-accc-16045cdef0a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from statsmodels.stats.weightstats import ttest_ind\n",
        "\n",
        "#generate random data with mean, std, size as above sample.\n",
        "## equal variance\n",
        "rvmale=np.random.normal(loc=malemean, scale=std, size=nmale)\n",
        "rvmale_fix = (rvmale - np.mean(rvmale)) * (std / np.std(rvmale)) + malemean #fix mean problem\n",
        "rvfemale=np.random.normal(loc=femalemean, scale=std, size=nfemale)\n",
        "rvfemale_fix = (rvfemale - np.mean(rvfemale)) * (std / np.std(rvfemale)) + femalemean #fix mean problem\n",
        "\n",
        "t_val, pval, df=ttest_ind(rvmale_fix, rvfemale_fix, alternative='two-sided', usevar='pooled', value=0)\n",
        "conclusion=testeval(0.01, pval)\n",
        "print(f'Calculated T value: {t_val:.4f}\\nPvalue is: {pval:.4f} \\nConclusion on Null Hypothesis given {0.01} significance level: {conclusion}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated T value: -4.4085\n",
            "Pvalue is: 0.0000 \n",
            "Conclusion on Null Hypothesis given 0.01 significance level: Rejected\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6boQjYn2ruZ6",
        "colab_type": "code",
        "outputId": "ea6c8968-59b3-44c8-8fcc-59b6dd4a2819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "## unequal variance\n",
        "rvmale=np.random.normal(loc=malemean, scale=stdmale, size=nmale)\n",
        "rvmale_fix = (rvmale - np.mean(rvmale)) * (stdmale / np.std(rvmale)) + malemean #fix mean problem\n",
        "rvfemale=np.random.normal(loc=femalemean, scale=stdfemale, size=nfemale)\n",
        "rvfemale_fix = (rvfemale - np.mean(rvfemale)) * (stdfemale / np.std(rvfemale)) + femalemean #fix mean problem\n",
        "\n",
        "t_val, pval, df=ttest_ind(rvmale_fix, rvfemale_fix, alternative='two-sided', usevar='unequal', value=0)\n",
        "conclusion=testeval(0.01, pval)\n",
        "print(f'Calculated T value: {t_val:.4f}\\nPvalue is: {pval:.4f} \\nConclusion on Null Hypothesis given {0.01} significance level: {conclusion}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated T value: -4.6591\n",
            "Pvalue is: 0.0000 \n",
            "Conclusion on Null Hypothesis given 0.01 significance level: Rejected\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxYt1RnZu2QF",
        "colab_type": "text"
      },
      "source": [
        "How to interpret the result?\n",
        "\n",
        "Given that the null hypothesis is true, there is a probability of 0.000005 (5.21345e-06) of obtaining a result equally or more extreme. We are 99% confident that the population difference in hours of sport per week between males and females is between -2.4817 and -0.7183 hours per week."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMMTVNLlv29p",
        "colab_type": "text"
      },
      "source": [
        "## Comparing two proportions for paired sample - McNemar's Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kActllXBwTK1",
        "colab_type": "text"
      },
      "source": [
        "Working with dependent data, such as twins, couples, same subject from different time, we will need to use different methods from above.\n",
        "\n",
        "> Example\n",
        "<br> Our research question here is whether there is a difference between the proportion of surveyed individuals that approve of the European union and the proportion of their partners that approve of the European union. What would be a good pair of hypotheses?\n",
        "<br>Answer\n",
        "<br>$H_0$: The proportion of EU approval is not different in surveyed individuals and their partners. $H_1$: The proportion of EU approval is different in surveyed individuals and their partners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7rKbgGnwitc",
        "colab_type": "code",
        "outputId": "e2f4723c-3163-4857-dd6a-7fac3ccc19b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "col_index=pd.MultiIndex.from_tuples([('Partner Approves of the EU', 'Yes'), ('Partner Approves of the EU', 'No')])\n",
        "row_index=pd.MultiIndex.from_tuples([('Survey Individuals that approve of the EU', 'Yes'),('Survey Individuals that approve of the EU', 'No')])\n",
        "survey = pd.DataFrame(np.array([[150, 50], [35, 100]]), index=row_index, columns=col_index)\n",
        "survey['row_totals'] = survey.sum(axis=1)\n",
        "s=survey.sum(axis=0)\n",
        "s.name='column_totals'\n",
        "survey = survey.append(s)\n",
        "display(survey)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Partner Approves of the EU</th>\n",
              "      <th>row_totals</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Yes</th>\n",
              "      <th>No</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(Survey Individuals that approve of the EU, Yes)</th>\n",
              "      <td>150</td>\n",
              "      <td>50</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(Survey Individuals that approve of the EU, No)</th>\n",
              "      <td>35</td>\n",
              "      <td>100</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>column_totals</th>\n",
              "      <td>185</td>\n",
              "      <td>150</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Partner Approves of the EU  ... row_totals\n",
              "                                                                        Yes  ...           \n",
              "(Survey Individuals that approve of the EU, Yes)                        150  ...        200\n",
              "(Survey Individuals that approve of the EU, No)                          35  ...        135\n",
              "column_totals                                                           185  ...        335\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSSpckQ2z9cr",
        "colab_type": "code",
        "outputId": "5e36de59-0915-4b87-c3f8-ead90297ff62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#calculate z value\n",
        "z_val=(50-35)/np.sqrt(50+35)\n",
        "\n",
        "#get pvalue\n",
        "pval=(1-st.norm.cdf(np.abs(z_val)))*2\n",
        "siglevel=0.05\n",
        "conclusion=testeval(siglevel, pval)\n",
        "print(f'Calculated Z value: {z_val:.4f}\\nPvalue is: {pval:.4f} \\nConclusion on Null Hypothesis given {siglevel} significance level: {conclusion}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated Z value: 1.6270\n",
            "Pvalue is: 0.1037 \n",
            "Conclusion on Null Hypothesis given 0.05 significance level: Not enough evidence to reject\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmSns86h4c3l",
        "colab_type": "text"
      },
      "source": [
        "The equivalent [mcnemar's test](http://www.statsmodels.org/dev/generated/statsmodels.stats.contingency_tables.mcnemar.html) in statsmodelss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi9KErQf28lk",
        "colab_type": "code",
        "outputId": "10eba6a2-c061-432c-b9c0-d35ce0511bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "result = mcnemar(survey.iloc[:2, :2].to_numpy(), exact=False, correction=False)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pvalue      0.1037416782365415\n",
            "statistic   2.6470588235294117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hmbdO1w9tWE",
        "colab_type": "text"
      },
      "source": [
        "## Compare two means for paired samples\n",
        "\n",
        "> Example\n",
        "<br>An example when we would do this is if we would want to know the effectiveness of a diet on people's weight. Our research question here is whether the diet that we have invented leads to a reduction in weight. As such our research question is directional. What would be a good set of hypotheses?\n",
        "<br>Answer: \n",
        "<br>$H_0$: There is no difference in people's weight before and after the diet. $H_1$: There is a reduction in weight after taking the diet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkaA6SeN6ibh",
        "colab_type": "code",
        "outputId": "c557c377-2ce0-4f38-e2a6-7b7981e22584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#generate data\n",
        "pre_weight=np.random.normal(loc=81.53587, scale=8.113578, size=100)\n",
        "pre_weight_fix=(pre_weight-np.mean(pre_weight))*(8.113578/np.std(pre_weight))+81.5358\n",
        "\n",
        "post_weight=np.random.normal(loc=78.20945, scale=9.223542, size=100)\n",
        "post_weight_fix=(post_weight-np.mean(post_weight))*(9.223542/np.std(pre_weight))+78.20945\n",
        "\n",
        "# get the difference of the two means\n",
        "diff = pre_weight_fix.mean()-post_weight_fix.mean()\n",
        "\n",
        "#standard deviation of the differences\n",
        "stddiff = np.std(pre_weight_fix-post_weight_fix)\n",
        "\n",
        "#standard error of the difference\n",
        "se=stddiff/np.sqrt(100)\n",
        "\n",
        "tval=diff/se \n",
        "pval=(1-st.t.cdf(np.abs(tval), 100-1))*2\n",
        "siglevel=0.05\n",
        "conclusion=testeval(siglevel, pval)\n",
        "print(f'Calculated t value: {tval:.4f}\\nPvalue is: {pval:.4f} \\nConclusion on Null Hypothesis given {siglevel} significance level: {conclusion}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculated t value: 2.3788\n",
            "Pvalue is: 0.0193 \n",
            "Conclusion on Null Hypothesis given 0.05 significance level: Rejected\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCTNnyPWuxaf",
        "colab_type": "text"
      },
      "source": [
        "# Categorical Association"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ZOoNtJve07",
        "colab_type": "text"
      },
      "source": [
        "## Chi-square"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tngpfiREv-lH",
        "colab_type": "text"
      },
      "source": [
        "We would like to find the association between two categorical varianbes. In below example, we are an advertisement company that have collected data coming from three different groups: Student, Parent, and Corporate. We are interested to know which ad type interests which group, so we can invest corresponding ads in those groups. Below data shows votes from different audience groups on their favorite ads: Party, Child, Office. \n",
        "\n",
        "To be specific, we need to find out two things:\n",
        "1.   Is the ad type has any association with audience group?\n",
        "2.   If there's association, which audience is in favor of which ad type?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbZJi392BMVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "7da3fe09-ccd3-4e61-e40f-0a8d9c6accd7"
      },
      "source": [
        "data = pd.DataFrame(np.array([[12, 5, 6],[7, 15, 7],[5, 5, 14]]), columns=['Party', 'Child', 'Office'], index=['Student', 'Parent', 'Corporate'])\n",
        "display(data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Child</th>\n",
              "      <th>Office</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Student</th>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parent</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Corporate</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Party  Child  Office\n",
              "Student       12      5       6\n",
              "Parent         7     15       7\n",
              "Corporate      5      5      14"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK7MbKp_xuLw",
        "colab_type": "text"
      },
      "source": [
        "We can conduct chi-square test to test the association between two categorical variables using scipy modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk4GbCMsv834",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "c248b5c0-6144-4bb5-880f-77ab93fccfa3"
      },
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "c_stat, pval, df, expected_val = chi2_contingency(data)\n",
        "expected_val = expected_val.round(1)\n",
        "\n",
        "print('Expected Value if these two categorical varianbles are not related:')\n",
        "display(expected_val)\n",
        "\n",
        "print('Calculated P value: {}'.format(pval))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected Value if these two categorical varianbles are not related:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 7.3,  7.6,  8.2],\n",
              "       [ 9.2,  9.5, 10.3],\n",
              "       [ 7.6,  7.9,  8.5]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Calculated P value: 0.005408290803578588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9k9MdN3yS4Z",
        "colab_type": "text"
      },
      "source": [
        "Here we can see that the expected values are far off from the observed data. Moreover, there are only 0.5% chance to observe such data if audience group has nothing to do with advertisement type. Hene, we rejected the null hypothesis in favor of the alternative hypothesis, i.e. the audience group has preference on their ad type. \n",
        "\n",
        "But how strong is this association? We can use Cramer's V to check its strength, where 0 means no association, and 1 is perfect. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OniHoPVSyJfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6cdcfac-7968-4114-832b-9d3e936d59a8"
      },
      "source": [
        "n=data.sum().sum() #the total number of observation\n",
        "m=min(data.shape)-1 #either the number of rows or columns whichever the smallest - 1\n",
        "cramerV=np.sqrt(c_stat/(n*m))\n",
        "print(cramerV)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3107928316933293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkSjU7sp2PPU",
        "colab_type": "text"
      },
      "source": [
        "Cramers V is about 0.31, which is pretty modest.\n",
        "\n",
        "But which ads is preferred or least preferred by each audience group? We can use standard residusals to see where there is the most deviation from the expected values.\n",
        "\n",
        "To standardise our residuals we need to divide each residual value by its standard error. We can directly get this value by using statsmodel api."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1oDjes5zFdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "6884a9a5-0e9f-4e93-9458-8d9b5427de64"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "# need to make a contingency table format\n",
        "table = sm.stats.Table(data)\n",
        "\n",
        "#standardized residuals\n",
        "table.standardized_resids"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Child</th>\n",
              "      <th>Office</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Student</th>\n",
              "      <td>2.544487</td>\n",
              "      <td>-1.363592</td>\n",
              "      <td>-1.132685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parent</th>\n",
              "      <td>-1.096214</td>\n",
              "      <td>2.744428</td>\n",
              "      <td>-1.629494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Corporate</th>\n",
              "      <td>-1.369141</td>\n",
              "      <td>-1.520432</td>\n",
              "      <td>2.822363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Party     Child    Office\n",
              "Student    2.544487 -1.363592 -1.132685\n",
              "Parent    -1.096214  2.744428 -1.629494\n",
              "Corporate -1.369141 -1.520432  2.822363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boDl3J583zLO",
        "colab_type": "text"
      },
      "source": [
        "From this you can see that the biggest values are for the student + party cell, parent + child cell and the corporate + office cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AwBkp2M0I0a",
        "colab_type": "text"
      },
      "source": [
        "## Chi-square goodness of fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqcsKxlO0L7A",
        "colab_type": "text"
      },
      "source": [
        "Your null hypothesis is that 60% of college students go to parties regularly, 30% go occaisionally and 10% never go. You want to test if your observed data matched this proportions. The solution of this question will be very similar to the above question. The difference will be you will need to calculate the expected counts based on the expected proportions listed in null hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4tuxsB41UIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "6d8db75e-cc84-4d97-9d62-f76cde45f947"
      },
      "source": [
        "exp_p=np.array([0.6, 0.3, 0.1]) #expected proportions\n",
        "exp_count=data.loc['Student'].sum()*exp_p\n",
        "display(pd.DataFrame([exp_count, data.loc['Student']], index=['expected', 'observed'], columns=data.columns))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Child</th>\n",
              "      <th>Office</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>expected</th>\n",
              "      <td>13.8</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>observed</th>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Party  Child  Office\n",
              "expected   13.8    6.9     2.3\n",
              "observed   12.0    5.0     6.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YcezOua1ZpX",
        "colab_type": "text"
      },
      "source": [
        "We can see that `Office` group deviates the most from expected values. We will be using [chisqure](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html) to get test statistic and p value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ErVW0vT0_G1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "81be48e5-6ae9-4828-e262-9ad2fdb934d5"
      },
      "source": [
        "from scipy.stats import chisquare\n",
        "c_stat, pval = chisquare(data.loc['Student'], f_exp=exp_count)\n",
        "print(f'chi square: {c_stat:.4f}\\n p value: {pval:.4f}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chi square: 6.7101\n",
            " p value: 0.0349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QYEmycp3Qhx",
        "colab_type": "text"
      },
      "source": [
        "As the calculated p value is smaller than 0.05 significance level, we rejected the null hypothesis. It means college students in our sample differed from the expected distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCKEvc-N4FP0",
        "colab_type": "text"
      },
      "source": [
        "## Fisher's Exact Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUGpufao6Sh4",
        "colab_type": "text"
      },
      "source": [
        "One of the assumption for chi-squre test is the minimum count in each cell is 5. When this assumption is not met, we can use Fisher's Exact Test to check two categorical variables' association.\n",
        "\n",
        "Fisher's exact test compares the observed values to a probability distribution. We find this comparison distribution by examining all possible rearrangements of our table. The restrictions are that the marginal frequencies must be the same.\n",
        "\n",
        "> Example\n",
        "<br>You had expected that parents would like the ad with a child in it because you thought that people with children like children more.\n",
        "To investigate this further, you took a sample of 15 adults, asked them whether or not they have children, and whether or not they like children. The results are saved in your console as a 2x2 table named child.\n",
        "\n",
        "We can perform Fisher's exact test using the function [fisher_exact](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.fisher_exact.html).\n",
        "\n",
        "> Null Hpothesis:\n",
        "<br> $H_0$: The two variables are independent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFBZOXH11oTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "d995666d-cd5c-4bd7-e8de-86cda2a5079d"
      },
      "source": [
        "child = pd.DataFrame(np.array([[7, 10], [1, 9]]), columns=['like', 'dislike'], index=['children', 'nochildren'])\n",
        "display(child)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>like</th>\n",
              "      <th>dislike</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nochildren</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            like  dislike\n",
              "children       7       10\n",
              "nochildren     1        9"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8SyvEPI60PG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bd6918b6-121c-4cd1-86c7-79ea177d52e8"
      },
      "source": [
        "from scipy.stats import fisher_exact\n",
        "odds_ratio, pval = fisher_exact(child, alternative='two-sided')\n",
        "print(f'Odds ratio: {odds_ratio:.4f}\\n p value: {pval:.4f}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Odds ratio: 6.3000\n",
            " p value: 0.1895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qepx_BCm9D6H",
        "colab_type": "text"
      },
      "source": [
        "The probability that we would observe this or an even more imbalanced ratio by chance is about 18.95%. Using significance level at 5%, we cannot conclude that our observed imbalance is statistically significant; \n",
        "there is probably not an association between having children and liking them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKEtCtem-Ou4",
        "colab_type": "text"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpBS-7c9KKLB",
        "colab_type": "text"
      },
      "source": [
        "## Simple Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P5aAi8H-4Kc",
        "colab_type": "text"
      },
      "source": [
        "For simple linear regresion, we focus on two parameters: intercept, and slope. The intercept is the value of the response variable when the predictor is 0. If we do not have any predictors(i.e. no other clues), the average of response variable is a common choise for estimation.\n",
        "\n",
        "There are many ways to get these two parameters in Python. You can check this [blog](https://www.freecodecamp.org/news/data-science-with-python-8-ways-to-do-linear-regression-and-measure-their-speed-b5577d75f8b/) to choose your favorite. Here I will use [linregress](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.linregress.html) function from scipy, and [OLS](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) function from statsmodel.\n",
        "\n",
        "> Example:\n",
        "Does people like you because you give them money?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvDI7KmR7_xg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "99d6096c-9fa3-4998-a6f8-40c2cb375e1e"
      },
      "source": [
        "#from scipy\n",
        "money  = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) #predictor\n",
        "liking = np.array([2.2, 2.8, 4.5, 3.1, 8.7, 5.0, 4.5, 8.8, 9.0, 9.2]) #response\n",
        "\n",
        "slope, intercept, correlation, pval, stderror=st.linregress(money, liking)\n",
        "rsquared = correlation**2\n",
        "\n",
        "result = pd.DataFrame([slope, intercept, correlation, pval, stderror, rsquared], index='slope, intercept, correlation, pval, stderror, rsquared'.split(', '), columns=['values']).round(4)\n",
        "display(result)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>slope</th>\n",
              "      <td>0.7782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intercept</th>\n",
              "      <td>1.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>correlation</th>\n",
              "      <td>0.8303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pval</th>\n",
              "      <td>0.0029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stderror</th>\n",
              "      <td>0.1847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rsquared</th>\n",
              "      <td>0.6893</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             values\n",
              "slope        0.7782\n",
              "intercept    1.5000\n",
              "correlation  0.8303\n",
              "pval         0.0029\n",
              "stderror     0.1847\n",
              "rsquared     0.6893"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n71lwIGMByv3",
        "colab_type": "text"
      },
      "source": [
        "From correlation of 0.8303, there is a strong positive correlation: the more money you give someone, the more they like you. But even if we do not give them any money, i.e. predictor =0, people like you an amount of 1.50 any way. Furthermore, the r-squared explains how well the predictor describes the response variable. And the p value of 0.0029 shows this model is significant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGOoxPmMEzbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "a43fbe78-8e4b-4607-b6d9-c691af7564a8"
      },
      "source": [
        "#from statsmodel\n",
        "import statsmodels.api as sm\n",
        "money = sm.add_constant(money)\n",
        "results = sm.OLS(liking, money).fit()\n",
        "print(results.summary())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.689\n",
            "Model:                            OLS   Adj. R-squared:                  0.650\n",
            "Method:                 Least Squares   F-statistic:                     17.75\n",
            "Date:                Thu, 13 Feb 2020   Prob (F-statistic):            0.00294\n",
            "Time:                        10:31:20   Log-Likelihood:                -18.248\n",
            "No. Observations:                  10   AIC:                             40.50\n",
            "Df Residuals:                       8   BIC:                             41.10\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          1.5000      1.146      1.309      0.227      -1.143       4.143\n",
            "x1             0.7782      0.185      4.213      0.003       0.352       1.204\n",
            "==============================================================================\n",
            "Omnibus:                        2.154   Durbin-Watson:                   2.826\n",
            "Prob(Omnibus):                  0.341   Jarque-Bera (JB):                0.506\n",
            "Skew:                           0.537   Prob(JB):                        0.776\n",
            "Kurtosis:                       3.244   Cond. No.                         13.7\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
            "  \"anyway, n=%i\" % int(n))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ehkpog1Go9t",
        "colab_type": "text"
      },
      "source": [
        "From statsmodel, Statsmodel has a comprehensive summary that is useful for analysis. `R-squared:` tells us how much of the variance in the response variable (liking) is explained by the predictor variable (money); `Prob (F-statistic)` gives the probability of observations given all regression coefficients equal zero is true,i.e. there will be no relationship between money and liking. Under 0.05 significance level, we will reject the null hypothesis and conclude this model is significant. The parameters are returned with P value indicating their significance as well(ho: each parameter is zero). If we have more predictors, this table will be useful for variable selection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRyTHFGtJzJX",
        "colab_type": "text"
      },
      "source": [
        "## Testing Assumptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPOhJpTrA92Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StvNaRTHBMrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}