{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829de7e3-355e-46d1-8874-b9771fc89cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a579ba-3748-4666-8679-2bfb8934f74f",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "Bootstrapping = Sampling with replacement\n",
    "\n",
    "1. Randomly choose a sample\n",
    "2. Write it down\n",
    "3. Put it back in the data (replacement)\n",
    "4. Repeat\n",
    "\n",
    "â€¢ Bootstrapped sample = Sample generated from bootstrapping\n",
    "\n",
    "\n",
    "## Non-parametric confidence interval\n",
    "\n",
    "- Non-parametric analogue of stats.norm.interval\n",
    "- Sample with replacement\n",
    "- Compute test statistic\n",
    "- Record it\n",
    "- Repeat\n",
    "- Creates an empirical distribution\n",
    "\n",
    "### Normal confidence intervals vs Bootstrap confidence intervals\n",
    "\n",
    "**Normal confidence intervals**\n",
    "\n",
    "- Requires data to be normally distributed\n",
    "- Computed based only on mean and\n",
    "standard error\n",
    "- Inference valid only for normal data\n",
    "- Very fast to compute\n",
    "  \n",
    "**Bootstrap confidence intervals**\n",
    "- Allows for any distribution\n",
    "- Computed directly from data by resampling\n",
    "- Inference valid for any data\n",
    "- Much slower to compute\n",
    "\n",
    "**Use cases for bootstrapping**\n",
    "\n",
    "- When working with non-normal data\n",
    "- Ranked data\n",
    "- Skewed data\n",
    "- When normal confidence intervals return questionable values\n",
    "- Work with any statistic we like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffdb49e-8f59-42ea-a291-3b5aa56b0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "investments_df = pd.read_csv('https://assets.datacamp.com/production/repositories/6125/datasets/3605df54bcd4f5dec36590c3724f594fa5a3890d/investments_VC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4547093-f562-4e71-a54d-5f7350695178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal CI: (-695062.1822300982, 4049988.441010135)\n",
      "Bootstrap CI: ConfidenceInterval(low=340562.0619718085, high=7641944.643204782)\n"
     ]
    }
   ],
   "source": [
    "# Select just the companies in the Analytics market\n",
    "analytics_df = investments_df[investments_df['market'] == 'Analytics']\n",
    "\n",
    "# Confidence interval using the stats.norm function\n",
    "norm_ci = stats.norm.interval(confidence=0.95,\n",
    "                             loc=analytics_df['private_equity'].mean(),\n",
    "                             scale=analytics_df['private_equity'].std() / np.sqrt(analytics_df.shape[0]))\n",
    "\n",
    "# Construct a bootstrapped confidence interval\n",
    "bootstrap_ci = stats.bootstrap(data=(analytics_df['private_equity'], ),\n",
    "                              statistic=np.mean)\n",
    "\n",
    "print('Normal CI:', norm_ci)\n",
    "print('Bootstrap CI:', bootstrap_ci.confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ac1aa-ce72-4f62-929d-b0ae1fc8c686",
   "metadata": {},
   "source": [
    "These two return quite different results, even though they're estimating the same thing! The primary reason for the difference is that the mean is relatively small and spread out, so the standard error is large. That causes the normal confidence interval to contain negative values.\n",
    "\n",
    "Q: Why are negative values in the confidence interval problematic for inference?\n",
    "\n",
    "A: Since the average private equity funding cannot be negative, conclusions from this confidence interval are questionable.\n",
    "\n",
    "Q: Why, on the other hand, does the bootstrap confidence interval not contain negative values?\n",
    "\n",
    "A: A bootstrap confidence interval is created by sampling from the original data, which does not contain negative values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d0554d-efc6-4425-8181-e40069d5be5b",
   "metadata": {},
   "source": [
    "## Combining evidence from p-values\n",
    "\n",
    "Researchers may come to different conclusions of the same experiment. Why?\n",
    "\n",
    "- Different samples - Different conclusions\n",
    "- Culprit: Effect size\n",
    "\n",
    "Solution: Testing a list of p-values that validate the same Null Hypothesis\n",
    "- Fisher's method\n",
    "    - Different samples/studies\n",
    "    - Same null hypothesis\n",
    "    - Different p-values\n",
    "    - At least one should reject the null\n",
    "- Combines evidence from multiple studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7784a6f7-d645-4f90-a32f-612bb060019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "p_values = [0.052, 0.12, 0.09, 0.051]\n",
    "fishers_stat, p_value = stats.combine_pvalues(p_values)\n",
    "print(p_value < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef55a06-a54c-4ba4-a577-3052096bf85d",
   "metadata": {},
   "source": [
    "Above 4 experiments testing the same null hypothesis are all less than 0.05 significance level, however they are quite close to the significance level. The combined_pvalues test has the a P value <0.05. Thus, we can conclude that, while no test individually showed statistical significance, the combination of evidence from all of the tests suggest there is indeed a significant effect present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b36058-eaf1-489b-a9a2-eb0d0f0b4ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "p_values = [0.01, 0.51, 0.81, 0.49]\n",
    "fishers_stat, p_value = stats.combine_pvalues(p_values)\n",
    "print(p_value < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e1e50-08c1-4fb5-93a7-eedfeab90f70",
   "metadata": {},
   "source": [
    "Contrast that with the case where one study had a low p-value of zero-point-zero-one, and yet all others had significantly larger p-values. In this case, Fisher's method suggests that none of the studies should have rejected the null, and perhaps the one study which did is merely a fluke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d6de4-352a-4eb3-a2f3-e2bc7cc337bc",
   "metadata": {},
   "source": [
    "## Permutation tests\n",
    "- Shuffles samples\n",
    "- Observes outcome\n",
    "- Observed difference looks like a random outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b022888-d7ec-4a43-9192-af2defaf28fa",
   "metadata": {},
   "source": [
    "**Permutation tests for mean difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8dee1ce-3e9d-4b03-8fb9-0130136bcae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2976190476190476\n"
     ]
    }
   ],
   "source": [
    "new_satisfaction = [94, 85, 79, 91, 82]\n",
    "old_satisfcation = [90, 87, 77, 85, 82]\n",
    "\n",
    "# Group together our data\n",
    "data = (new_satisfaction, old_satisfcation)\n",
    "\n",
    "# Define our test statistic\n",
    "def statistic(x, y):\n",
    "    return np.mean (x) - np.mean (y)\n",
    "\n",
    "# Compute a permutation test for the difference in means\n",
    "res = stats. permutation_test(data, statistic, n_resamples=1000, vectorized=False, alternative='greater')\n",
    "print(res.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a1e26c-ba00-4a79-b7de-8b6ad1a46a6f",
   "metadata": {},
   "source": [
    "## Permutation tests vs Bootstrapping\n",
    "\n",
    "**Permutation tests**\n",
    "- Build a null distribution by randomly shuffling data\n",
    "- Tests for significance of an outcome\n",
    "\n",
    "**Bootstrapping**\n",
    "- Build a probability distribution by randomly sampling data\n",
    "- Creates a confidence interval showing most likely outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0f6425-4147-475b-859c-3a93a515060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_sp_df=pd.read_csv('https://assets.datacamp.com/production/repositories/6125/datasets/62594304a29e7820dd01ee8970456ef9decf8aa2/btc_sp.csv')\n",
    "btc_sp_df['Pct_Daily_Change_BTC']=(btc_sp_df['Open_BTC']-btc_sp_df['Close_BTC'])/btc_sp_df['Open_BTC']\n",
    "btc_sp_df['Pct_Daily_Change_SP500']= (btc_sp_df['Open_SP500']-btc_sp_df['Close_SP500'])/btc_sp_df['Open_SP500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2158224-9ce7-4365-bbb9-e5911d948c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define a function which returns the Pearson R value\n",
    "def statistic(x, y):\n",
    "\treturn stats.pearsonr(x,y)[0]\n",
    "\n",
    "# Define the data as the percent daily change from each asset\n",
    "data = (btc_sp_df['Pct_Daily_Change_BTC'],btc_sp_df['Pct_Daily_Change_SP500'])\n",
    "\n",
    "# Compute a permutation test for the percent daily change of each asset\n",
    "res = stats.permutation_test(data, statistic, \n",
    "           n_resamples=1000,\n",
    "           vectorized=False, \n",
    "           alternative='greater')\n",
    "\n",
    "# Print if the p-value is significant at 5%\n",
    "print(res.pvalue < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f02a81-4a4c-44ec-b117-8124d1d47ef8",
   "metadata": {},
   "source": [
    "Notice how the ability to conduct this test hinged only on your ability to write a statistic function and collect data! Hopefully this shows you the power of a permutation test, and how it can be used in a broad range of situations. You put absolutely no assumptions on your data, and yet you were still able to conclude that the observed greater volatility in Bitcoin over SP500 is indeed statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b274615-2c09-4058-af1a-66b7c732e36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
